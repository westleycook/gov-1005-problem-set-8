---
title: "Problem Set 8"
author: "Westley Cook"
date: "4/15/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# standard first load

library(tidyverse)

# for its data

library(fivethirtyeight)

# for skim()

library(skimr)

# for tidy()

library(broom)

# for gt() tables

library(gt)

# loading data

load("raw-data/tweetsnew.Rdata")

```

## Question 1: Exploratory Data Analysis

### 1A) Summary Statistics

```{r question_1a,echo=FALSE}

# This r chunk finds the number of Trump tweets per week and binds that data to
# the fivethirtyeight Trump approval rating data. It then prints a call to the
# skim() function to view summary stats for total tweets and approval rating

# Renaming the approval rating data from fivethirtyeight so it's shorter and
# more wieldy

poll <- trump_approval_poll

# Finding number of tweets per week. Grouping by week and counting, then
# renaming the n column to total_tweets as specified in question prompt

tweets_by_week <- tweets %>% 
  group_by(week) %>% 
  count() %>% 
  rename(total_tweets = n)

# Adding week column to poll data using code from the assignment prompt

poll$week <- ceiling(as.numeric(difftime(poll$end_date, 
                                         "2017-01-01", 
                                         units = "days")
                                )/7)

# Joining tweet data with approval rating poll data replacing all NA tweet
# values with 0 (could have used replace_na() for this instead, but I forgot
# that function existed until after I'd already used mutate() and tested to make
# sure it was working, so I didn't want to change it)

approval_tweets <- poll %>% 
  left_join(tweets_by_week, by = "week") %>% 
  mutate(total_tweets = ifelse(is.na(total_tweets), 0, total_tweets))

# Selecting columns specified in the assignment prompt and printing summary
# stats using skim()

approval_tweets %>% 
  select(total_tweets, approve) %>% 
  skim()


```

### 1B) Bivariate Correlations

```{r question_1b, echo=FALSE}

# This r chunk plots approval rating by total number of tweets and grade of the
# poll. It then finds the correlation coefficient for approval rating and number
# of tweets

# Creating the plot. Use fct_explicit_na() around grade to force it to show
# missing values. Manually set color scheme to viridis and give the legend a
# name (note: not an exact replicate of assignment prompt plot, because I've
# capitalized "Grade" in the legend title, and they didn't - but I think it
# looks better this way). All other text and formatting replicates the
# assignment prompt plot exactly

approval_tweets %>% 
  ggplot(aes(total_tweets, approve, color = fct_explicit_na(grade))) +
  geom_point() +
  theme_classic() +
  labs(title = "Trump Approval Ratings and Number of Tweets",
       subtitle = "Data from fivethirtyeight and Trump Twitter Archive",
       x = "Total Tweets",
       y = "Approval Rating") +
  scale_color_viridis_d(name = "Grade")

# Finding correlation coefficient for approval rating and total tweets, then
# pulling the value and assigning it to an object, which I insert in-line below

cor_coef <- approval_tweets %>% 
  summarize(cor = cor(total_tweets, approve)) %>% 
  pull(cor) %>% 
  round(digits = 3)

```


The correlation coefficient between the approval rating and the number of tweets is **`r cor_coef`**. There does NOT seem to be a strong relationship between tweet activity and approval ratings.

## Question 2: Multivariate Regression

### 2A) Using lm()

```{r question_2a, echo=FALSE}

# This r chunk runs a linear regression of approval ratings on two variables,
# total_tweets and high_q (whether the poll was high quality or not)

# Using mutate() and ifelse() to create the new high_q variable

new_approval_tweets <- approval_tweets %>% 
  mutate(high_q = ifelse(grade %in% c("A+", "A", "A-"),
                         1,
                         0))

# Running a linear regression of approval rating on total_tweets and high_q,
# using tidy() to make the model results easy to work with and conf.int = TRUE
# to grab the upper and lower bounds of a 95% confidence interval. Then
# selecting just the variables of interest and mutating to round them each to a
# few significant digits. Finally, piping them to a gt table and adding a title,
# subtitle, and column labels

new_approval_tweets %>% 
  lm(approve ~ total_tweets + high_q, data = .) %>% 
  tidy(conf.int = TRUE) %>% 
  select(term, estimate, conf.low, conf.high) %>% 
  mutate(estimate = round(estimate, digits = 3),
         conf.low = round(conf.low, digits = 3),
         conf.high = round(conf.high, digits = 4)) %>% 
  gt() %>% 
  tab_header(title = "Effect of Number of Tweets and Poll Quality on Reported 
             Approval Rating",
             subtitle = "Data from fivethirtyeight and Trump Tweet Archive") %>% 
  cols_label(term = "Variable",
             estimate = "Estimate",
             conf.low = "Lower Bound",
             conf.high = "Upper Bound")

```

### 2B) Interpreting Results

The estimated average treatment effect of high_q is -2.347, which means that taking into account all other variables in the model, a high-quality poll is expected to produce an approval rating roughly 2.3 points *lower* than a low-quality poll.

The frequentist interpretation of the confidence interval is that 95% of the time, using the process we used will generate an interval containing the true value of the average treatment effect of each variable on approval rating. The Bayesian interpretation is that there is a 95% chance that the interval we created here contains the true value of the average treatment effect.

### 2C) Interaction Variables

```{r question_2c, echo=FALSE}

# This r chunk runs a new regression that includes total_tweets, high_q, and the
# interaction between total tweets and high quality. It then prints the results
# in a gt table like the one above

# Code here was copied and pasted directly from 2a, with the following edits:

# 1) the lm() call was changed from total_tweets + high_q to total_tweets *
# high_q in order to generate the interaction term

# 2) conf.high was rounded to 3 digits instead of four

new_approval_tweets %>% 
  lm(approve ~ total_tweets * high_q, data = .) %>% 
  tidy(conf.int = TRUE) %>% 
  select(term, estimate, conf.low, conf.high) %>% 
  mutate(estimate = round(estimate, digits = 3),
         conf.low = round(conf.low, digits = 3),
         conf.high = round(conf.high, digits = 3)) %>% 
  gt() %>% 
  tab_header(title = "Effect of Number of Tweets and Poll Quality on Reported 
             Approval Rating",
             subtitle = "Data from fivethirtyeight and Trump Tweet Archive") %>% 
  cols_label(term = "Variable",
             estimate = "Estimate",
             conf.low = "Lower Bound",
             conf.high = "Upper Bound")

```

### 2D) Estimating Fitted Values

This model would predict that for Monmouth University's A+ rated poll during a week in which President Trump tweeted 84 times, the approval rating would be as follows:

Predicted approval rating = Intercept estimate - high_q + (total_tweets + total_tweets:high_q) * number of tweets

Predicted approval rating = 41.629 - 2.701 + (-0.006 + 0.021) * 84 = **40.188**

Calculating the predicted value using R's predict() function, we get almost exactly the same result (discrepancy due to roundoff error):

```{r question_2d}
  
# Naming the interaction model

interaction_model <- lm(approve ~ total_tweets * high_q, 
                        data = new_approval_tweets)

# Predicting the model's result given a high-quality poll and 84 tweets

predict(interaction_model, tibble(total_tweets = 84, high_q = 1))

```

### 2E) Multiple Regression and the Rubin Causal Model

Taking into account all other variables in the model, the coefficient for total_tweets would be the average expected treatment effect for each unit of total_tweets (presumably one tweet) when democrat = 0. In other words, it’s the slope of the line when democrat = 0 (which presumably means the respondent was Republican).

The coefficient for democrat would be the *offset* from the baseline intercept when democrat = 1; the baseline intercept is the expected approval rating if total_tweets = 0 and democrat = 0 (in other words, the expected Republican approval rating if the president doesn’t tweet). So the expected approval rating when democrat = 1 and total_tweets = 0 (or in other words, the expected approval rating for a Democrat when the president doesn’t tweet) would be the baseline intercept *plus* this coefficient.

The coefficient for total_tweets:democrat would be the *offset* from the coefficient for total_tweets when democrat = 1. So the slope of the line when democrat = 1 (presumably meaning the respondent is a Democrat) would be the coefficient for total_tweets *plus* this coefficient.

This seems to be an explanatory model, because it’s attempting to isolate the magnitude of the effect of each variable (total_tweets, democrat, and total_tweets:democrat). If it were a predictive model, it would care more about just getting an accurate prediction than it would about the respective magnitudes of each variable in the model.



